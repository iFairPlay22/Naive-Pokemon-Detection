{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a933425",
   "metadata": {},
   "source": [
    "# 4I SI2 - Mini projet Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf78db6",
   "metadata": {},
   "source": [
    "## Sommaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce7e93c",
   "metadata": {},
   "source": [
    "* [Introduction](#introduction)\n",
    "* [Etat de l'art](#etat_de_lart)\n",
    "    * [Convolutional Neural Networks](#cnn)\n",
    "    * [Regression Logistique](#regression_logistique)\n",
    "    * [K-plus proche voisin](#knn)\n",
    "    * [K-means](#kmeans)\n",
    "    * [Choix de la méthode utilisée](#choix_methode)\n",
    "* [Pokédex](#pokedex)\n",
    "    * [Présentation détaillée de la solution](#solution_detail)\n",
    "    * [Comment tester chez vous ?](#test)\n",
    "* [Conclusion](#ccl)\n",
    "* [Ressources](#ressources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739d3f2d",
   "metadata": {},
   "source": [
    "## Introduction <a class=\"anchor\" id=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f86c16",
   "metadata": {},
   "source": [
    "Dans le but de créer une application de reconnaissance de Pokémon, type Pokedex, il nous a été demandé de developper la partie reconnaissance de Pokémon. Afin de réaliser cet objectif, nous utiliserons une méthode de reconnaissance d'image.<br/>\n",
    "Dans un second temps, nous detaillerons une méthode que nous trouverons la plus adaptée a notre problématique et nous essayerons de la mettre en oeuvre. <br/>\n",
    "Enfin nous concluerons sur les resultats que nous obtiendrons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610c76c8",
   "metadata": {},
   "source": [
    "<img src=\"https://assets.pokemon.com/assets/cms2/img/pokedex/full/025.png\" style=\"width: 100px;\"></img>\n",
    "<img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--ugAVgNoo--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://cdn-images-1.medium.com/max/2000/0%2A0Y5OTBWR-YCcfel5.png\" style=\"width: 500px;\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc2fdd9",
   "metadata": {},
   "source": [
    "## Etat de l'art de la reconnaissance d'images <a class=\"anchor\" id=\"etat_de_lart\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26912ac",
   "metadata": {},
   "source": [
    "La reconnaissance d'images, est une sous-catégorie de la vision par ordinateur et de l'intelligence artificielle. Elle représente un ensemble de méthodes de détection et d'analyse d'images permettant l'automatisation d'une tâche spécifique. Il s'agit d'une technologie capable d'identifier des lieux, des personnes, des objets et de nombreux autres types d'éléments dans une image, et d'en tirer des conclusions en les analysant.<br/>\n",
    "\n",
    "Il existe donc différentes \"tâches\" que la reconnaissance d'images peut effectuer : \n",
    "\n",
    "- La classification. C'est l'identification de la \"classe\", c'est-à-dire de la catégorie à laquelle appartient une image. Une image ne peut avoir qu'une seule classe.  \n",
    "- Le marquage. Il s'agit également d'une tâche de classification, mais avec un degré de précision plus élevé. Elle permet de reconnaître la présence de plusieurs concepts ou objets dans une image. Une ou plusieurs étiquettes peuvent donc être attribuées à une image particulière.  \n",
    "- Détection. Cette tâche est nécessaire lorsque l'on veut localiser un objet dans une image. Une fois l'objet localisé, une boîte de délimitation est placée autour de l'objet en question.   \n",
    "- Segmentation. Il s'agit également d'une tâche de détection. La segmentation permet de localiser un élément sur une image au pixel près. Dans certains cas, il est nécessaire d'être extrêmement précis, comme pour le développement des voitures autonomes.\n",
    "\n",
    "Ainsi pour notre problématique, nous utiliserons une tache de classification d'images. Il s'agit d'un problème d'apprentissage supervisé, c'est à dire qu'il est capable réaliser une tâche d'apprentissage automatique consistant à apprendre une fonction de prédiction à partir d'exemples annotés. Il s'agit, dans un premier temps, de définir un ensemble de classes cibles (objets à identifier dans les images) et d'entraîner un modèle à les reconnaître à l'aide de photos exemples labelées. <br/>\n",
    "Les premiers modèles de vision par ordinateur s'appuyaient sur des données de pixels brutes comme entrée du modèle. Cependant, les données de pixels brutes ne fournissent pas à elles seules une représentation suffisamment stable pour englober la multitude de variations d'un objet capturé dans une image. La position de l'objet, l'arrière-plan derrière l'objet, l'éclairage ambiant, l'angle de la caméra et la mise au point de la caméra peuvent tous produire des fluctuations dans les données de pixels brutes ; ces différences sont suffisamment importantes pour ne pas pouvoir être corrigées en prenant des moyennes pondérées des valeurs RVB des pixels. <br/>\n",
    "Nous étudierons différentes méthodes utilisées dans la reconnaissance d'images, et réaliserons un descriptif succincte de celles-ci."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bdc76f",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks <a class=\"anchor\" id=\"cnn\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec509343",
   "metadata": {},
   "source": [
    "Au lieu de prétraiter les données pour en extraire des caractéristiques telles que les textures et les formes, un réseau neuronal convolutif prend en entrée les données brutes des pixels de l'image et \"apprend\" à extraire ces caractéristiques, pour finalement déduire l'objet qu'elles constituent. <br/>\n",
    "Afin de réaliser cette prédiction, le modèle reçoit une carte de caractéristiques en entrée : une matrice tridimensionnelle où la taille des deux premières dimensions correspond à la longueur et à la largeur des images en pixels. La taille de la troisième dimension est 3 (correspondant aux 3 canaux d'une image couleur : rouge, vert et bleu). Le modèle est composé d'une pile de modules, chacun d'entre eux effectuant trois opérations.<br/>\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/2000/1*vkQ0hXDaQv57sALXAJquxA.jpeg\" style=\"width: 700px;\"></img>\n",
    "\n",
    "#### Convolution\n",
    "\n",
    "Une convolution extrait des portions de la carte de caractéristiques (matrice) d'entrée et leur applique des filtres pour calculer de nouvelles caractéristiques, produisant une carte de caractéristiques de sortie, ou caractéristique convoluée. Cette matrice de sortie peut avoir une taille et une profondeur différentes de celle de la carte de caractéristique. <br/>\n",
    "<img src=\"https://developers.google.com/machine-learning/practica/image-classification/images/convolution_overview.gif\" style=\"width: 700px;\"></img>\n",
    "\n",
    "#### ReLU\n",
    "\n",
    "Après chaque opération de convolution, le modèle applique une transformation ReLU (Rectified Linear Unit) à la caractéristique de sortie de la convolution, afin d'introduire une non-linéarité dans le modèle. La fonction ReLU, renvoie x pour toutes les valeurs de x > 0, et renvoie 0 pour toutes les valeurs de x ≤ 0. <br/>\n",
    "\n",
    "#### Pooling\n",
    "\n",
    "Après ReLU vient une étape de pooling, dans laquelle le modèle sous-échantillonne la caractéristique de sortie de ReLU (pour gagner du temps de traitement), réduisant ainsi le nombre de dimensions de la carte de caractéristiques, tout en préservant les informations les plus critiques de la caractéristique. Un algorithme couramment utilisé pour ce processus est appelé max pooling. <br/>\n",
    "\n",
    "<img src=\"https://developers.google.com/machine-learning/practica/image-classification/images/maxpool_animation.gif\" style=\"width: 700px;\"></img>\n",
    "\n",
    "À la fin d'un réseau neuronal convolutif se trouvent une ou plusieurs couches entièrement connectées. Leur tâche consiste à effectuer une classification sur la base des caractéristiques extraites par les convolutions. En général, la dernière couche entièrement connectée contient une fonction d'activation softmax, qui produit une valeur de probabilité de 0 à 1 pour chacune des étiquettes de classification que le modèle tente de prédire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfaeafe",
   "metadata": {},
   "source": [
    "### Regression logistique <a class=\"anchor\" id=\"regression_logistique\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd4b8dc",
   "metadata": {},
   "source": [
    "La régression logistique est une méthode d'analyse statistique qui consiste à prédire une valeur de données d'après les observations réelles d'un jeu de données. Cette approche permet d'utiliser un algorithme dans l'application d'apprentissage automatique pour classer les données entrantes en fonction des données historiques.<br/>\n",
    "Cette méthode est particulièrement efficace sur la classification binaire, c'est à dire, qui a deux issues possibles. Mais on peut également faire de la classification multi classes, c'est à dire, avec plusieurs issues possibles.\n",
    "Il faut alors trouver une ligne capable de délimiter les ensembles.<br/>\n",
    "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/classification-1.png\" style=\"width: 500px;\"></img>\n",
    "<img src=\"https://miro.medium.com/max/972/1*SwXHlCzh-d9UqHOglp3vcA.png\" style=\"width: 500px;\"></img>\n",
    "\n",
    "Le traitement a effectuer ensuite est différent en fonction de la classification a effectuer (binaire ou multi classes).\n",
    "\n",
    "#### Classification binaire (Sigmoid Function)\n",
    "\n",
    "La regression logistique est un modèle de classification linéaire, quand Y ne doit prendre que deux valeurs possibles (0 ou 1). Le modèle étant linéaire, la fonction hypothèse pourra s'écrire : $ S(X) = \\sum \\limits _{i=0} ^{n+1} {\\theta}_{i}x_{i} $. <br/>\n",
    "Avec :\n",
    "- $X$ : une observation, cette variable est un vecteur contenant $x_{0}, x_{1},..., x_{n}$.\n",
    "- $x_{i}$ : est une variable prédictive qui servira dans le calcul du modèle prédictif.\n",
    "- ${\\theta}_{i}$ : est un poids/paramètre de la fonction hypothèse. Ce sont ces ${\\theta}_{i}$ qu’on cherche à calculer pour obtenir notre fonction de prédiction.\n",
    "\n",
    "Cette fonction est appelée la fonction **score**. L’idée est alors de trouver des coefficients $ {\\theta}_{0}, {\\theta}_{1}, …,{\\theta_{n}} $ de sorte que :\n",
    "\n",
    "- $S(X) > 0$ quand la classe vaut valeur 1\n",
    "- $S(X) < 0$ quand la classe vaut valeur 0\n",
    "\n",
    "Cette fonction score obtenue intègre les différentes variables prédictive $x_{i}$. On y appliquera ensuite, la fonction **sigmoid** qui permet de produire des valeurs comprises entre 0 et 1. Le résultat obtenu peut être alors interprété comme la probabilité qui l'observation $X$ soit la valeur 1.\n",
    "\n",
    "La fonction sigmoid, est définie par $Sigmoid(x) = \\frac{1}{1 + e^{-x}}$.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/53/Sigmoid-function-2.svg/2560px-Sigmoid-function-2.svg.png\" style=\"width: 500px;\"></img>\n",
    "\n",
    "En appliquant cette fonction sigmoid a notre fonction score, nous obtenons la fonction suivante : $H(X)=\\frac{1}{1 + e^{S(X)}}$. <br/>\n",
    "Pour interpreter les résultats, si $H(X)=0.3$, cela signifie que $X$ a 30% de chance d'être la valeur 1.\n",
    "\n",
    "#### Classification multi classes (Algorithme All-vs-One)\n",
    "\n",
    "L'algorithme All-vs-One consiste à découper le problème de classification multi-classes en une multitude de problèmes de classification binaires.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*RElrybCZ4WPsUfRwDl7fqA.png\" style=\"width: 500px;\"></img>\n",
    "\n",
    "1. On considère que les triangles sont la classe positive et le reste comme la classe négative (dans ce cas, les carrés et les croix seront dans le même groupe de classe négative), et on entraîne la régression logistique sur cette configuration de données. Ce qui produira une fonction de prédiction $H^1(X)$.\n",
    "2. On considère les carrés comme la classe positive et le reste comme la classe négative, et on entraîne la régression logistique pour obtenir une deuxième fonction de prédiction : $H^2(X)$.\n",
    "3. On considère les croix comme la classe positive et le reste comme la classe négative, et on entraîne la régression logistique pour obtenir $H^3(X)$.\n",
    "\n",
    "Chacune des ces fonctions de prédiction $H^1(X)$, $H^2(X)$ et $H^3(X)$ nous donnera la probabilité que $X$ soit de la classe étudiée respectivement. La bonne classe de l’observation x est celle pour laquelle on a obtenu la plus grande probabilité. $max(H^1(X),H^2(X),...,H^n(X))$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adcd5a1",
   "metadata": {},
   "source": [
    "### K-plus proches voisins <a class=\"anchor\" id=\"knn\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a60b7e",
   "metadata": {},
   "source": [
    "La méthode des K-plus proches voisins est une méthode de régression et de classification. Elle fait partie des méthodes les plus utilisées car elle est très simple. <br/>\n",
    "Il s'agit d'une méthode non paramétriques, c'est à dire une méthode pour laquelle nous n'effectuons pas d'hypothèse de paramètres, qui mémorise les observations de l'ensemble d'apprentissage pour la classification de l'ensemble de tests. <br/>\n",
    "Ainsi, la méthode est définie comme étant paresseuse car elle n'apprend rien pendant la phase d'entrainement.<br/>\n",
    "Afin de prédire la classe d'une donnée, elle va chercher ses K voisins les plus proches par le calcul de la distance euclidienne par la formule : <br/>\n",
    "$\\sum \\limits _{i=1} ^{n} | x_{i}-y_{i} |$ \n",
    "<br/>\n",
    "Une fois la distance euclidienne calculée autour de notre nouvelle donnée, il nous suffit de calculer le nombre d'élèments de chaque classe présent dans ce périmètre et choisir la classe majoritaire comme étant la classe d'appartenance de cette donnée.\n",
    "<br/>\n",
    "<img src=\"https://miro.medium.com/max/810/1*0Pqqx6wGDfFm_7GLebg2Hw.png\" style=\"width: 300px;\"></img>\n",
    "<br/>\n",
    "Afin d'appliquer cette méthode, nous devons dans un premier temps fixer le nombre de voisin K. Pour ce faire, nous devons faire plusieurs essais en faisant varier K. Pour chaque K, nous devons calculer le taux d'erreur sur l'ensemble de test et ainsi choisir celui qui minimise ce taux d'erreur. <br/>\n",
    "L'importance dans le choix de notre K est illustré dans le schema ci-dessus. Ainsi, nous visualisons que si nous choisissons : \n",
    "- K=3, la nouvelle entrée appartiendrait à la classe A\n",
    "- K=5, la nouvelle entrée appartiendrait à la classe B\n",
    "<br/>\n",
    "<img src=\"https://datascientest.com/wp-content/uploads/2020/11/Illu-4-KNN-1536x856.jpg.webp\" style=\"width: 600px;\"></img>\n",
    "<br/>\n",
    "Nous visualisons alors avec le résultat de l'évolution du taux d'erreur en fonction du nombre de K voisins, que la valeur de K voisins à choisir est en 5 et 18. <br/>\n",
    "Dans cet exemple, pour $K > 18$, nous observons un phénomène de sur-apprentissage, c'est à dire que le modèle explique trop bien les données mais ne parvient pas à faire des prédictions utiles pour les nouvelles données.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a9afeb",
   "metadata": {},
   "source": [
    "### K-means <a class=\"anchor\" id=\"kmeans\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f24695",
   "metadata": {},
   "source": [
    "L'algorithme K-means est l'algorithme de clustering le plus simple, c'est à dire qu'il permet d'effectuer une analyse statistique utilisée pour organiser des données brutes en silos homogènes.<br/> \n",
    "Il permet donc de réaliser des analyses non supervisées, de regrouper les individus ayant des caractéristiques similaires. Lorsque l'on doit créer des groupes d'individus on commence généralement par cet algorithme qui est la plus simple à mettre en oeuvre.<br/>\n",
    "<br/>\n",
    "Nous allons vous présenter les étapes à effectuer afin de réaliser ce clustering. <br/>\n",
    "\n",
    "1. Nous devons dans un premier temps initialiser le nombre de groupe que nous souhaitons en effectuant un tirage aléatoire du nombre d'individu égal au nombre de groupe voulu. Ces individus seront les centres initiaux des classes.\n",
    "<br/>\n",
    "<img src=\"https://www.lovelyanalytics.com/wp-content/uploads/2017/03/lovelyanalytics_kmeans1-1.jpg\" style=\"width: 400px;\"></img>\n",
    "*Dans cet exemple, nous réalisons un tirage de trois individus représentant les centres initiaux de 3 classes.*\n",
    "<br/>\n",
    "<br/>\n",
    "2. Ensuite, pour chaque individu de la base de données, nous realisons un calcul de distance euclidienne par rapport à chaque centre précèdemment tirés. \n",
    "<br/>\n",
    "<img src=\"https://www.lovelyanalytics.com/wp-content/uploads/2017/03/lovelyanalytics_kmeans2-1.jpg\" style=\"width: 400px;\"></img>\n",
    "<br/>\n",
    "3. On affecte alors chaque individu à la classe de centre le plus proche.\n",
    "<br/>\n",
    "<img src=\"https://www.lovelyanalytics.com/wp-content/uploads/2017/03/lovelyanalytics_kmeans3-1.jpg\" style=\"width: 400px;\"></img>\n",
    "<br/>\n",
    "4. On calcul alors les centres de gravité des groupes qui deviennent les nouveaux centres.\n",
    "<br/>\n",
    "<img src=\"https://www.lovelyanalytics.com/wp-content/uploads/2017/03/lovelyanalytics_kmeans4-1.jpg\" style=\"width: 400px;\"></img>\n",
    "<br/>\n",
    "5. Nous recommençons les étapes 2, 3, 4 tant que les individus sont réaffectés à de nouveaux groupes après une itération.\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7f7cfa",
   "metadata": {},
   "source": [
    "### Choix de la méthode utilisée <a class=\"anchor\" id=\"choix_methode\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07f8d87",
   "metadata": {},
   "source": [
    "|Méthodes étudiées|CNN|Régression linéaire|KNN|K-means|\n",
    "|---|---|---|---|---|\n",
    "|Avantages (+) | Méthode très fiable  |Simple à mettre en oeuvre|Simple à mettre en oeuvre <br/> Pas necessaire de créer un modèle ni de regler plusieurs paramètres|Faible temps de calcul|\n",
    "|Inconvénients (-) | Demande beaucoup de ressources |Des valeurs abérantes peuvent subvenirs|Devient beaucoup plus lent lorsque le nombre de variable indépendantes augmente|Choix du nombre de groupes|\n",
    "\n",
    "Ainsi, nous nous avons pu éliminer la Convolutionnal Nerronal Network puisque sur nos ordinateurs, il nous aurait été impossible de changer les pondérations de nos neurones par manque de puissance de calcul. <br/>\n",
    "Il nous reste alors à faire le choix entre la régression lineaire, K-plus proches voisins et K-means.<br/>\n",
    "<br/>\n",
    "Nous avons finalement choisi de travailler avec K-means puisque nous voulons dans un premier temps créer des clusters correspondant à chaque Pokémon que nous avons en base.<br/>\n",
    "Une fois ce clustering effectué, lorsque nous voudrons reconnaitre un nouveau pokémon, nous effectuerons le même traitement qu'avec toutes les images de la base de test puis nous effectuerons un calcul de distance euclidienne avec les différents clusters de pokémon afin de l'affecter au groupe le plus proche et donc de le reconnaitre.\n",
    "<br/>\n",
    "<br/>\n",
    "**Choix final : K-Means**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4db324",
   "metadata": {},
   "source": [
    "## Pokédex <a class=\"anchor\" id=\"pokedex\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b74d112",
   "metadata": {},
   "source": [
    "Nous vous rappelons que notre objectif initial est d'être capable de reconnaitre les Pokémons de la première génération afin d'effectuer un Pokédex. Nous allons vous présenter la méthode de machine learning que nous avons utilisé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6076ee4",
   "metadata": {},
   "source": [
    "### Présentation détaillée de la solution <a class=\"anchor\" id=\"solution_detail\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771dbcd",
   "metadata": {},
   "source": [
    "Notre approche de machine learning se base sur la reconnaissance d'image par représentation d’histogramme de couleur.<br/>\n",
    "\n",
    "Pour cela, nous devons extraire dans un premier temps les “features” de nos images. Nous mesurons la similarité de ces images grâce aux features de notre base d'entraînement et de notre image de référence et pourrons alors trier les images par rapport à leur similarité avec l’image de référence recherchée.<br/>\n",
    "\n",
    "Dans un premier temps, nous devons récupérer et trier votre liste d’images. Nous avons à notre disposition des informations sur les pokémons ('pokedex_number' et 'name') au format CSV mais surtout différents datasets de pokémons de la génération 1. <br/>\n",
    "Nous trions les banques d’image pour associer chacune des images à l’ID du pokémon auquel elle correspond. Nos multiples banques sont triés de différentes manières mais nous pouvons parvenir à nos fins en nous basant sur l’ID du pokémon. <br/>\n",
    "Nous avons donc toutes nos images liées à un pokémon. Il y a pour chaque pokémon plusieurs dizaines d'images, ce qui va nous permettre d'avoir déjà une bonne base pour travailler.<br/>\n",
    "\n",
    "Il serait très long de détailler tout le processus de triage des images de pokémons. Le contenu de la fonction ```getLearningDataset()``` dans le fichier ```init.py``` dans le dossier ```load``` nous retourne l’ensemble des images de pokémons contenues dans les datasets à notre disposition triés par ID.<br/>\n",
    "\n",
    "Maintenant que notre banque d’image est claire, nous allons traiter les images pour en obtenir leurs histogrammes de couleur. \n",
    "La problématique avec les histogrammes de couleurs est la dimension que chaque image représente avec toutes les couleurs disponibles. SI nous décidons d’utiliser les images tels qu’elles, nous aurions des vecteurs à 16777216 dimensions, peu efficaces. \n",
    "Nous effectuons donc une quantification de couleur, permettant de trouver les couleurs les plus couramment utilisées parmis toutes les images. L’échantillon de couleurs obtenus est très grand et nous en sélectionnons aléatoirement 100000 parmi l’échantillon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05865b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Entrée :\n",
    "    - numpy array images ;\n",
    "    - int pixelNumber ;\n",
    "\n",
    "Sortie :\n",
    "    - numpy array randomRbgPixels ;\n",
    "\n",
    "Description:\n",
    "    Retourne ${pixelNumber} pixels RGB de manière aléatoire depuis\n",
    "    le dataset fourni en paramètre\n",
    "\"\"\"\n",
    "def _getRandomRgbPixels(self, pixelNumber=100000):\n",
    "    allRgbPixels = [img.reshape((-1, 3)) for img in self._imgs]\n",
    "    allRgbPixels = np.vstack(allRgbPixels)\n",
    "    randomPixelsIndexes = np.random.choice(\n",
    "        allRgbPixels.shape[0], pixelNumber, replace=False)\n",
    "    randomRbgPixels = allRgbPixels[randomPixelsIndexes, :]\n",
    "    return randomRbgPixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d357a32f",
   "metadata": {},
   "source": [
    "Nous utilisons ensuite l’algorithme des K-Means pour déterminer les N (128) couleurs les plus courantes. Nous bâtissons donc un modèle prédictif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ac8def5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Entrée :\n",
    "    - numpy array randomRbgPixels ;\n",
    "\n",
    "Sortie :\n",
    "    - KMeans kms ;\n",
    "\n",
    "Description:\n",
    "    Applique l'algorithme de KMeans sur les pixels. On regarde les occurences\n",
    "    des pixels dans l'image, afin de pouvoir batir un modèle prédictif.\n",
    "\"\"\"\n",
    "\n",
    "def _getKMeans(self, pixels):\n",
    "    nombre_pokemon = 151\n",
    "    kms = KMeans(nombre_pokemon, n_init=1, verbose=0)\n",
    "    kms.fit(pixels)\n",
    "\n",
    "    h = np.zeros((kms.n_clusters, ))\n",
    "    for i in range(kms.n_clusters):\n",
    "        r, g, b = kms.cluster_centers_[i, :]/255.0\n",
    "        h[i] = colorsys.rgb_to_hsv(r, g, b)[0]\n",
    "    idx = np.argsort(h)\n",
    "    kms.cluster_centers_ = kms.cluster_centers_[idx, :]\n",
    "\n",
    "    if (self._consts.getDisplayImagePalette()):\n",
    "        palette = kms.cluster_centers_.astype(np.uint8)\n",
    "        self._displayImg(palette.reshape((8, -1, 3)))\n",
    "\n",
    "    return kms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5f4481",
   "metadata": {},
   "source": [
    "Nous devons donc ensuite calculer l’histogramme de couleur pour chacune des images ainsi que celle de référence et les renvoyons dans notre matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "053cb7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Entrée :\n",
    "    - KMeans kms ;\n",
    "    - numpy array img ;\n",
    "\n",
    "Sortie :\n",
    "    - numpy array histogram ;\n",
    "\n",
    "Description:\n",
    "    On revoie l'histogramme des couleurs de l'image.\n",
    "\"\"\"\n",
    "\n",
    "def _getImgHistogram(self, kms, img):\n",
    "    x = np.zeros((kms.n_clusters, ))\n",
    "    idx = kms.predict(img.astype(np.float64).reshape((-1, 3)))\n",
    "    idv, v = np.unique(idx, return_counts=True)\n",
    "    x[idv] = v\n",
    "    return x/np.sum(x).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822667d0",
   "metadata": {},
   "source": [
    "Nous recherchons ensuite par similarité les distances euclidiennes entre les images d'entraînement et celles de référence et sélectionnons l’image qui à la plus grande correspondance avec celle de référence. <br/>\n",
    "\n",
    "Nous pouvons déduire quel nom de pokémon se rapproche le plus de l’image de référence et pouvons fournir un résultat à l’utilisateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "304ed4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    Entrée  : \n",
    "        - numpy array img ;\n",
    "        - int imgNumber ;\n",
    "\n",
    "    Sortie  : \n",
    "        -  int pokemonId ;\n",
    "\n",
    "    Description :\n",
    "        On compare les diagrammes de couleurs de l'image et de celles enregistrées \n",
    "        dans le dataset. On retourne le pokemonId le plus proche.\n",
    "\"\"\"\n",
    "\n",
    "def predict(self, img, imgNumber=5):\n",
    "    imgHistogram = self._getImgHistogram(self._kms, img)\n",
    "    dist = euclidean_distances([imgHistogram], self._histograms)\n",
    "    sortDist = np.argsort(dist[0, :])\n",
    "\n",
    "    foundPokemonIds = [self._ids[sortDist[i]] for i in range(imgNumber)]\n",
    "\n",
    "    return most_common(foundPokemonIds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ad2ed2",
   "metadata": {},
   "source": [
    "Comme nos images sont triées, nous pouvons récupérer le nom du Pokémon associé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a19d441",
   "metadata": {},
   "source": [
    "### Comment tester chez vous ? <a class=\"anchor\" id=\"test\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abb5645",
   "metadata": {},
   "source": [
    "Vous devez téléchargez l'archive We-transfer via ce lien : [We-transfer]() <br>\n",
    "Placez le dossier téléchargé et décompressé dans le dossier `assets` et assurez vous que ce dossier est correctement nommé `images`.<br>\n",
    "Assurez-vous d'avoir tous les dépendances python cités dans le `README`, rubrique `Dépendances`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946cb227",
   "metadata": {},
   "source": [
    "## Conclusion <a class=\"anchor\" id=\"ccl\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e56b733",
   "metadata": {},
   "source": [
    "Nous avons effectué des tests de reconnaissance sur tous les Pokemons de toutes les génération à notre disposition. De plus étant donné que nos datasets d'apprentissages comportaient plus de pokémons que la génération 1, nous en avons profité pour étendre la reconnaissance à tous les Pokemons compris dans nos learning datasets.<br>\n",
    "En utilisant toutes ces données, les résultats fluctuent entre 35% et 40% de succès. Mais cela s'explique par l'abondance de Pokémons et donc de similarités entre eux.<br>\n",
    "\n",
    "Si l'on souhaite respecter notre idée initiale, il faut alors supprimer les images de Pokémons dont l'ID est supérieur à 151 présentes dans le répertoire `OneShotPokemon`.<br>\n",
    "Grâce à cela, l'algorithme ne va pas prendre en compte les Pokémons hors la génération 1. Ce changement va considérablement augmenter le taux de succès pour atteindre ~70% de réussite.<br>\n",
    "Nous expliquons cela par le fait que moins de Pokémons sont analysés, et donc moins de chances d'échouer sur la reconnaissance des histogrammes de couleur des Pokémons.<br>\n",
    "\n",
    "Nous remarquons que pour la plupart des erreurs, les images de Pokemons ayant un important espace vide et les Pokemons ayant un arrrière plan de teinte similaire à leur apparence ont plus de mal à être identifiés.\n",
    "|Minidraco (147)|Papilusion (12)|\n",
    "|---|---|\n",
    "|<img src = \"ScreenShots\\147.jpg\" width=350, height=350>|<img src = \"ScreenShots\\12.jpg\" width=350, height=350>|\n",
    "|L'impact de l'arrière plan est trop important <br> le fond représente ~70% de l'histogramme du pokémon|Le Pokemon possède les mêmes teintes sur ses ailes que le fond|\n",
    "\n",
    "A contrario, les Pokemons prenant le maximum de place sur l'image et possèdant des couleurs différentes que celles du fond ont des résultats bien plus satisfaisants.\n",
    "|Bulbizard (1)|Fantominus (92)|\n",
    "|---|---|\n",
    "|<img src = \"ScreenShots\\1.jpg\" width=350, height=350>|<img src = \"ScreenShots\\92.jpg\" width=350, height=350>|\n",
    "|Le Pokemon prends la majeure partie de l'image<br> Sa couleur principale est le vert|Le Pokemon prends la majeure partie de l'image<br> Sa couleur principale est le voilet/noir|\n",
    "\n",
    "Nous pensons que nous obtenons ces résultats puisque les images sont majoritairement composés de paysage en arrière plan, participant négativement à la reconnaissance de l'image puisque nous utilisons des histogrammes de couleurs. Afin d'améliorer ces résultats nous pourrions :\n",
    "- Détourer l'image en conservant seulement le Pokémon pour obtenir un histogramme de meilleur qualité.\n",
    "- Prendre des images de pokémon avec des arrières plans vides.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd22485",
   "metadata": {},
   "source": [
    "## Ressources <a class=\"anchor\" id=\"ressources\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155637a7",
   "metadata": {},
   "source": [
    "- [Google ML Practicum: Image Classification](https://developers.google.com/machine-learning/practica/image-classification?hl=en)\n",
    "- [Classifying Pokémon Images with Machine Learning](https://medium.com/m2mtechconnect/classifying-pok%C3%A9mon-images-with-machine-learning-79b9bc07c080)\n",
    "- [Regression lineaire mrmint](https://mrmint.fr/logistic-regression-machine-learning-introduction-simple)\n",
    "- [Regression lineaire whatis](https://whatis.techtarget.com/fr/definition/Regression-logistique)\n",
    "- [K-plus proche voisins](https://datascientest.com/knn)\n",
    "- [K-means](https://www.lovelyanalytics.com/2016/09/06/k-means-comment-ca-marche/)\n",
    "- [Dataset de Pokémon](https://www.kaggle.com/kvpratama/pokemon-images-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5a69c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
