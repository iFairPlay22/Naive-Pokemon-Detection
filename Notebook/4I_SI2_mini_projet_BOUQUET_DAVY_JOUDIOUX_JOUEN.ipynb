{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a933425",
   "metadata": {},
   "source": [
    "# 4I SI2 - Mini projet Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf78db6",
   "metadata": {},
   "source": [
    "## Sommaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce7e93c",
   "metadata": {},
   "source": [
    "* [Introduction](#introduction)\n",
    "* [Etat de l'art](#etat_de_lart)\n",
    "    * [Convolutional Neural Networks](#cnn)\n",
    "    * [Regression Logistique](#regression_logistique)\n",
    "    * [K-plus proche voisin](#knn)\n",
    "    * [K-means](#kmeans)\n",
    "    * [Choix de la méthode utilisée](#choix_methode)\n",
    "* [Pokédex](#pokedex)\n",
    "    * [Présentation détaillée de la solution](#solution_detail)\n",
    "    * [Comment tester chez vous ?](#test)\n",
    "* [Conclusion](#ccl)\n",
    "* [Ressources](#ressources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739d3f2d",
   "metadata": {},
   "source": [
    "## Introduction <a class=\"anchor\" id=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f86c16",
   "metadata": {},
   "source": [
    "Le but de ce projet est de recréer le principe du pokédex du jeu \"Pokémon\", mais à partir d'une source de données plus complexe, des images. Nous avons ainsi développé un programme en python permettant d'analyser des images de pokémons, afin de pouvoir les dissocier, et donc de reconnaître le pokémon représenté dans l'image.<br/><br/>\n",
    "\n",
    "Afin de réaliser ce projet, nous avons du nous renseigner sur le sujet, afin de connaître les méthodes les plus célèbres de reconaissance d'images. La première partie de ce rapport sera l'occasion de vous présenter notre compréhention de ces différents travaux. Ensuite, dans un second temps, nous detaillerons la méthode que nous avons utilisée afin de répondre à notre problématique. Enfin, nous concluerons en parlant des résultats obtenus, et la manière dont nous pouvons les améliorer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610c76c8",
   "metadata": {},
   "source": [
    "<img src=\"https://assets.pokemon.com/assets/cms2/img/pokedex/full/025.png\" style=\"width: 100px;\"></img>\n",
    "<img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--ugAVgNoo--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://cdn-images-1.medium.com/max/2000/0%2A0Y5OTBWR-YCcfel5.png\" style=\"width: 500px;\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc2fdd9",
   "metadata": {},
   "source": [
    "## Etat de l'art - La reconnaissance d'images <a class=\"anchor\" id=\"etat_de_lart\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26912ac",
   "metadata": {},
   "source": [
    "Pour commencer, la reconnaissance d'images est une sous-catégorie des domaines suivants :\n",
    "- La vision par ordinateur ;\n",
    "- L'intelligence artificielle ; \n",
    "\n",
    "Cette dernière représente un ensemble de méthodes de détection et d'analyse d'images permettant l'automatisation d'une tâche spécifique. En clair, il s'agit d'une technologie capable d'identifier des lieux, des personnes, des objets, etc. contenus dans une image. Cela va même parfois plus loin, car certains alhorithmes mènent des analyses plus complexes, permettant par exemple de tirer des conclusions sur divers sujets / diverses situations (ex : détection de l'état mental d'une personne, signalements de situations dangereuses via l'analayse de caméra de vidéo surveillance, etc).\n",
    "\n",
    "En particuler, il existe différentes \"tâches\" réalisables via la reconnaissance d'images : \n",
    "\n",
    "- La classification : C'est l'identification de la \"classe\", c'est-à-dire de la catégorie à laquelle appartient une image. Une image ne peut avoir qu'une seule classe.  \n",
    "- Le marquage : Il s'agit également d'une tâche de classification, mais avec un degré de précision plus élevé. Elle permet de reconnaître la présence de plusieurs concepts ou objets dans une image. Une ou plusieurs étiquettes peuvent donc être attribuées à une image particulière.  \n",
    "- La détection : Cette tâche est nécessaire lorsque l'on veut localiser un objet dans une image. Une fois l'objet localisé, une boîte de délimitation est placée autour de l'objet en question.   \n",
    "- La segmentation : Il s'agit également d'une tâche de détection. La segmentation permet de localiser un élément sur une image au pixel près. Dans certains cas, il est nécessaire d'être extrêmement précis, comme pour le développement des voitures autonomes.\n",
    "\n",
    "Dans le cadre de notre problème initial (pokédex), nous effectuerons une classification d'images. Nous utiliserons pour cela un apprentissage supervisé, car nous proposerons un apprentissage automatique se basant sur une fonction de prédiction portant sur des exemples annotés (donnée + réponse attendue). Dans un premier temps, nous définirons un ensemble de classes cibles (objets à identifier dans les images) et entraînerons le modèle à les reconnaître à l'aide de photos d'exemple labelisés. En clair, nous fournirons à notre IA une base de données de couples (x, y) tel que x est l'image d'un pokémons, et y est le nom associé (dans le but que l'IA retrouve y tout seul par la suite à partir de x). Cependant, même avec un apprentissage supervisé, cette tâche reste une tâche complexe.\n",
    "\n",
    "En effet, même si les premiers modèles de vision par ordinateur s'appuyent sur des données de pixels brutes comme entrée du modèle, ces derniers ne fournissent pas une représentation suffisamment stable pour englober la multitude de variations d'un objet capturé dans une image. Dans ce sens, la position de l'objet, l'arrière-plan (derrière l'objet), l'éclairage ambiant, l'angle de la caméra et sa mise au point peuvent tous produire des fluctuations dans les données de pixels brutes. Ces différences sont suffisamment importantes pour ne pas pouvoir être corrigées en prenant des moyennes pondérées des valeurs RVB des pixels. Il est donc difficile d'analyser les images, et de mettre en relation les différentes parties d'une image ensemble. Les résultats d'analyse consistent donc plus en des prédictions que des résultats parfaitement fiables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bdc76f",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks <a class=\"anchor\" id=\"cnn\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec509343",
   "metadata": {},
   "source": [
    "La première méthode de reconaissance d'images que nous avons choisi de présenter s'appelle \"Convolutional Neural Networks\", ou encore en français, les \"réseaux de neurones convolutifs\".\n",
    "\n",
    "\n",
    "Le principe est le suivant : au lieu de prétraiter les données pour en extraire des caractéristiques (telles que les textures et les formes par exemple), on soumet directement les données brutes des pixels d'une l'image à un réseau neuronal convolutif. Suite à un apprentissage, ce dernier va avoir la capacité d'en extraire des caractéristiques, ce qui permettra finalement d'en déduire l'objet constenu. \n",
    "\n",
    "\n",
    "Afin de réaliser cette prédiction, le modèle reçoit une matrice tridimensionnelle en entrée. En particulier, la taille de la matrice est longueur x largeur x 3. En clair, on associe chaque pixel de l'image (longueur x largeur) à sa valeur RGB (taux de concentration en rouge, vert et bleu). Le modèle neuronal est composé d'une pile de modules, chacun d'entre eux effectuant trois opérations successives : une convolution, un ReLu et un Pooling. Enfin, un algorithme de classification peut être mené afin de réaliser une prédiction. \n",
    "\n",
    "<img src=\"https://miro.medium.com/max/2000/1*vkQ0hXDaQv57sALXAJquxA.jpeg\" style=\"width: 700px;\"></img>\n",
    "\n",
    "#### Convolution\n",
    "\n",
    "La convolution consiste en la transformation de la carte de caractéristiques (matrice) d'entrée en une carte de caractéristiques (matrice) de sortie, aussi appelée caractéristique convoluée. Concrètement, cette dernière applique des filtres à chaque portions extraite afin de calculer de nouvelles caractéristiques. La matrice de sortie peut avoir une taille et une profondeur différente de celle de la carte de caractéristique, en fonction des calculs réalisés. \n",
    "\n",
    "<img src=\"https://developers.google.com/machine-learning/practica/image-classification/images/convolution_overview.gif\" style=\"width: 700px;\"></img>\n",
    "\n",
    "#### ReLU\n",
    "\n",
    "Après chaque opération de convolution, le modèle applique une transformation ReLU (Rectified Linear Unit) à la caractéristique de sortie de la convolution, afin d'introduire une non-linéarité dans le modèle. En particulier, la fonction ReLU est simple : \n",
    "- On renvoie renvoie x si x > 0 ;\n",
    "- On renvoie 0 sinon (x ≤ 0) ; \n",
    "\n",
    "#### Pooling\n",
    "\n",
    "Après ReLU vient une étape de pooling, dans laquelle le modèle sous-échantillonne la caractéristique de sortie de ReLU (afin de minimiser les temps de traitement). Ceci a pour effet de réduire ainsi le nombre de dimensions de la carte de caractéristiques, tout en préservant les informations les plus importantes / critiques de la caractéristique. Un algorithme couramment utilisé pour ce processus est appelé max pooling. Afin que le processus soit efficace, on le refait plusieurs fois via un système de cycle de convolution / ReLU / pooling (ex: 2 fois dans l'image plus haute).\n",
    "\n",
    "<img src=\"https://developers.google.com/machine-learning/practica/image-classification/images/maxpool_animation.gif\" style=\"width: 700px;\"></img>\n",
    "\n",
    "#### Classification\n",
    "\n",
    "À la fin d'un réseau neuronal convolutif, on trouve une ou plusieurs couches entièrement connectées. Il s'agit de faire une classification sur la base des caractéristiques extraites par les convolutions afin d'arriver à un résultat. En général, la dernière couche entièrement connectée contient une fonction d'activation softmax, qui produit une valeur de probabilité de 0 à 1 pour chacune des étiquettes de classification que le modèle tente de prédire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfaeafe",
   "metadata": {},
   "source": [
    "### Regression logistique <a class=\"anchor\" id=\"regression_logistique\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd4b8dc",
   "metadata": {},
   "source": [
    "La régression logistique est une méthode d'analyse statistique qui consiste à prédire une valeur de données d'après les observations réelles d'un jeu de données. Cette approche permet d'utiliser un algorithme dans l'application d'apprentissage automatique pour classer les données entrantes en fonction des données historiques. En particulier, on peut utiliser cette technique afin de dissocier deux types d'images (une image de chien ou de chat par exemple).<br/>\n",
    "\n",
    "Cette méthode est particulièrement efficace sur la classification binaire, c'est à dire à deux issues possibles. Cependant, on peut également faire de la classification multi classes (plus de 2 issues possibles).\n",
    "\n",
    "Il faut alors trouver un cas de figure ou on peut délimiter les ensembles à partir d'une droite (hypothèse de combinaison linéaires entre les données).<br/>\n",
    "\n",
    "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/classification-1.png\" style=\"width: 500px;\"></img>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/972/1*SwXHlCzh-d9UqHOglp3vcA.png\" style=\"width: 500px;\"></img>\n",
    "\n",
    "Le traitement à effectuer par la suite diffère en fonction de la classification à effectuer :\n",
    "- La fonction sigmoîde à partir pour une classification binaire ;\n",
    "- L'algorithme All-vs-One pour la classification multi classes ;\n",
    "\n",
    "#### Classification binaire (Sigmoid Function)\n",
    "\n",
    "La regression logistique est un modèle de classification linéaire, où Y ne peut prendre que deux valeurs possibles (0 ou 1). Le modèle étant linéaire, la fonction hypothèse pourra s'écrire : $ S(X) = \\sum \\limits _{i=0} ^{n+1} {\\theta}_{i}x_{i} $. <br/>\n",
    "Avec :\n",
    "- $X$ : une observation, cette variable est un vecteur contenant $x_{0}, x_{1},..., x_{n}$.\n",
    "- $x_{i}$ : est une variable prédictive qui servira dans le calcul du modèle prédictif.\n",
    "- ${\\theta}_{i}$ : est un poids/paramètre de la fonction hypothèse. Ce sont ces ${\\theta}_{i}$ qu’on cherche à calculer pour obtenir notre fonction de prédiction.\n",
    "\n",
    "Cette fonction est appelée la fonction **score**. L’idée est alors de trouver des coefficients $ {\\theta}_{0}, {\\theta}_{1}, …,{\\theta_{n}} $ de sorte que :\n",
    "\n",
    "- $S(X) > 0$ quand la classe vaut valeur 1 ;\n",
    "- $S(X) < 0$ quand la classe vaut valeur 0 ;\n",
    "\n",
    "La fonction score obtenue intègre les différentes variables prédictive $x_{i}$. On y appliquera ensuite, la fonction **sigmoide** qui permet de produire des valeurs comprises entre 0 et 1 (on retourne vers un résultat probabiliste). Le résultat obtenu peut être alors interprété comme la probabilité que l'observation $X$ soit la valeur 1.\n",
    "\n",
    "La fonction sigmoide, est définie par $Sigmoid(x) = \\frac{1}{1 + e^{-x}}$.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/53/Sigmoid-function-2.svg/2560px-Sigmoid-function-2.svg.png\" style=\"width: 500px;\"></img>\n",
    "\n",
    "En appliquant cette fonction au score, nous obtenons la fonction suivante : $H(X)=\\frac{1}{1 + e^{S(X)}}$. <br/>\n",
    "\n",
    "Pour interpreter les résultats, si $H(X)=0.3$, cela signifie que $X$ a 30% de chance d'être la valeur 1.\n",
    "\n",
    "#### Classification multi classes (Algorithme All-vs-One)\n",
    "\n",
    "L'algorithme All-vs-One consiste à découper le problème de classification multi-classes en une multitude de problèmes de classification binaire.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*RElrybCZ4WPsUfRwDl7fqA.png\" style=\"width: 500px;\"></img>\n",
    "\n",
    "1. On considère que les triangles sont la classe positive et le reste comme la classe négative (dans ce cas, les carrés et les croix seront dans le même groupe de classe négative), et on entraîne la régression logistique sur cette configuration de données. Ce qui produira une fonction de prédiction $H^1(X)$.\n",
    "2. On considère les carrés comme la classe positive et le reste comme la classe négative, et on entraîne la régression logistique pour obtenir une deuxième fonction de prédiction : $H^2(X)$.\n",
    "3. On considère les croix comme la classe positive et le reste comme la classe négative, et on entraîne la régression logistique pour obtenir $H^3(X)$.\n",
    "\n",
    "Chacune des ces fonctions de prédiction $H^1(X)$, $H^2(X)$ et $H^3(X)$ nous donnera la probabilité que $X$ soit de la classe étudiée respectivement. La bonne classe de l’observation x est celle pour laquelle on a obtenu la plus grande probabilité. $max(H^1(X),H^2(X),...,H^n(X))$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adcd5a1",
   "metadata": {},
   "source": [
    "### K-plus proches voisins <a class=\"anchor\" id=\"knn\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a60b7e",
   "metadata": {},
   "source": [
    "La méthode des K-plus proches voisins est une méthode de régression et de classification basée sur les centres de gravités de k points. Elle fait partie des méthodes les plus utilisées car elle repose sur un algorithme très simple. Dans le cadre du traitement d'images, on pourrait l'utiliser afin de prédire quelle image appartient à quel groupe. L'avantage de cette méthode par rapport à la regréssion logistique, est que l'on peut faire des prédictions viables pour des données n'étant pas forcément séparables pas une droite.\n",
    "\n",
    "\n",
    "Il s'agit d'une méthode non paramétrique, c'est à dire une méthode pour laquelle nous n'effectuons pas d'hypothèse des paramètres. En effet, cette dernière mémorise les observations de l'ensemble d'apprentissage pour la classification de l'ensemble de tests. Ainsi, la méthode est définie comme étant paresseuse car elle n'apprend rien pendant la phase d'entrainement.\n",
    "\n",
    "En effetn, afin de prédire la classe d'une donnée, elle va chercher ses K voisins les plus proches par le calcul de la distance euclidienne par la formule : <br/>\n",
    "$\\sum \\limits _{i=1} ^{n} | x_{i}-y_{i} |$ \n",
    "\n",
    "\n",
    "Une fois la distance euclidienne calculée autour de notre nouvelle donnée, il nous suffit de calculer le nombre d'élèments de chaque classe présent dans ce périmètre et choisir la classe majoritaire comme étant la classe d'appartenance de cette donnée.\n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/810/1*0Pqqx6wGDfFm_7GLebg2Hw.png\" style=\"width: 300px;\"></img>\n",
    "\n",
    "\n",
    "Afin d'appliquer cette méthode, nous devons dans un premier temps fixer le nombre de voisins K. Pour ce faire, nous devons faire plusieurs essais en faisant varier K. Pour chaque K, nous devons calculer le taux d'erreur sur l'ensemble de test et ainsi choisir celui qui minimise ce taux d'erreur. <br/>\n",
    "L'importance dans le choix de notre K est illustré dans le schema ci-dessus. Ainsi, nous visualisons que si nous choisissons : \n",
    "- K=3, la nouvelle entrée appartiendrait à la classe A ;\n",
    "- K=5, la nouvelle entrée appartiendrait à la classe B ;\n",
    "\n",
    "\n",
    "<img src=\"https://datascientest.com/wp-content/uploads/2020/11/Illu-4-KNN-1536x856.jpg.webp\" style=\"width: 600px;\"></img>\n",
    "\n",
    "\n",
    "Nous visualisons alors avec le résultat de l'évolution du taux d'erreur en fonction du nombre de K voisins, que la valeur de K voisins à choisir est en 5 et 18. \n",
    "\n",
    "Dans cet exemple, pour $K > 18$, nous observons un phénomène de sur-apprentissage, c'est à dire que le modèle explique trop bien les données mais ne parvient pas à faire des prédictions utiles pour les nouvelles données.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a9afeb",
   "metadata": {},
   "source": [
    "### K-means <a class=\"anchor\" id=\"kmeans\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f24695",
   "metadata": {},
   "source": [
    "L'algorithme K-means est l'algorithme de clustering le plus simple, c'est à dire qu'il permet d'effectuer une analyse statistique utilisée pour organiser des données brutes en silos homogènes.\n",
    "\n",
    "Il permet donc de réaliser des analyses non supervisées et de regrouper les individus ayant des caractéristiques similaires. Lorsque l'on doit créer des groupes d'individus, on commence généralement par cet algorithme car il est relativement simple à mettre en oeuvre.\n",
    "\n",
    "Nous allons vous présenter les étapes à effectuer afin de réaliser ce clustering :\n",
    "\n",
    "1. Nous devons dans un premier temps initialiser le nombre de groupes que nous souhaitons en effectuant un tirage aléatoire du nombre d'individu (égal au nombre de groupes voulus). Ces individus seront les centres initiaux des classes.\n",
    "\n",
    "<img src=\"https://www.lovelyanalytics.com/wp-content/uploads/2017/03/lovelyanalytics_kmeans1-1.jpg\" style=\"width: 400px;\"></img>\n",
    "\n",
    "*Dans cet exemple, nous réalisons un tirage de trois individus représentant les centres initiaux de 3 classes.*\n",
    "\n",
    "\n",
    "2. Ensuite, pour chaque individu de la base de données, nous realisons un calcul de distance euclidienne par rapport à chaque centre précèdemment tiré. \n",
    "\n",
    "\n",
    "<img src=\"https://www.lovelyanalytics.com/wp-content/uploads/2017/03/lovelyanalytics_kmeans2-1.jpg\" style=\"width: 400px;\"></img>\n",
    "\n",
    "\n",
    "3. On affecte alors chaque individu à la classe de centre le plus proche.\n",
    "\n",
    "\n",
    "<img src=\"https://www.lovelyanalytics.com/wp-content/uploads/2017/03/lovelyanalytics_kmeans3-1.jpg\" style=\"width: 400px;\"></img>\n",
    "\n",
    "\n",
    "4. On calcule ensuite les centres de gravité des groupes. Ceux-ci deviennent les nouveaux centres.\n",
    "\n",
    "\n",
    "<img src=\"https://www.lovelyanalytics.com/wp-content/uploads/2017/03/lovelyanalytics_kmeans4-1.jpg\" style=\"width: 400px;\"></img>\n",
    "\n",
    "\n",
    "5. Nous recommençons les étapes 2, 3, 4 tant que les individus sont réaffectés à de nouveaux groupes après une itération."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7f7cfa",
   "metadata": {},
   "source": [
    "### Choix de la méthode utilisée <a class=\"anchor\" id=\"choix_methode\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07f8d87",
   "metadata": {},
   "source": [
    "|Méthodes étudiées|CNN|Régression linéaire|KNN|K-means|\n",
    "|---|---|---|---|---|\n",
    "|Avantages (+) | Méthode très fiable  |Simple à mettre en oeuvre|Simple à mettre en oeuvre <br/> Pas necessaire de créer un modèle ni de regler plusieurs paramètres|Faible temps de calcul|\n",
    "|Inconvénients (-) | Demande beaucoup de ressources |Des valeurs abérantes peuvent subvenir si pas de combinaison linéaire|Devient beaucoup plus lent lorsque le nombre de variable indépendantes augmente|Choix du nombre de groupes|\n",
    "\n",
    "Nous nous avons éliminé le \"Convolutionnal Neuronal Network\", puisque'il nous aurait été impossible de charger les pondérations de nos neurones sur nos ordinateurs par manque de puissance de calcul.\n",
    "\n",
    "Nous avons écarté la régression lineaire, car cette méthode est inadaptée à notre problème. \n",
    "\n",
    "Nous avons donc finalement choisi K-means puisque nous voulons dans un premier temps créer des clusters de pixels correspondant aux pixels majoritaires que nous avons en base. Une fois ce clustering effectué, nous effectuerons un calcul de distance euclidienne entre les pixels normalisés de l'image à prédire et des piexels normalisés des autres images afin de catégoriser l'image au pokémon lui ressemblant le plus (méthode des gradients de couleurs d'images).\n",
    "\n",
    "**Choix final : K-Means**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4db324",
   "metadata": {},
   "source": [
    "## Pokédex <a class=\"anchor\" id=\"pokedex\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b74d112",
   "metadata": {},
   "source": [
    "Nous vous rappelons que notre objectif initial est d'être capable de reconnaitre des pokémons à partir d'une image. Nous allons vous présenter la méthode de machine learning que nous avons utilisé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6076ee4",
   "metadata": {},
   "source": [
    "### Présentation détaillée de la solution <a class=\"anchor\" id=\"solution_detail\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771dbcd",
   "metadata": {},
   "source": [
    "Notre approche de machine learning se base sur la reconnaissance d'image par représentation d’histogramme de couleurs.<br/>\n",
    "\n",
    "Pour cela, nous devons extraire dans un premier temps les “features” de nos images. Nous mesurons la similarité de ces images grâce aux features de notre base d'entraînement et de notre image de référence et pourrons alors trier les images par rapport à leur similarité avec l’image de référence recherchée.<br/>\n",
    "\n",
    "Dans un premier temps, nous devons récupérer et trier votre liste d’images. Nous avons à notre disposition des informations sur les pokémons ('pokedex_number' et 'name') au format CSV mais surtout différents datasets de pokémons de la génération 1. <br/>\n",
    "Nous trions les banques d’image pour associer chacune des images à l’ID du pokémon auquel elle correspond. Nos multiples banques sont triés de différentes manières mais nous pouvons parvenir à nos fins en nous basant sur l’ID du pokémon. <br/>\n",
    "Nous avons donc toutes nos images liées à un pokémon. Il y a pour chaque pokémon plusieurs dizaines d'images, ce qui va nous permettre d'avoir déjà une bonne base pour travailler.<br/>\n",
    "\n",
    "Il serait très long de détailler tout le processus de triage des images de pokémons. Le contenu de la fonction ```getLearningDataset()``` dans le fichier ```init.py``` dans le dossier ```load``` nous retourne l’ensemble des images de pokémons contenues dans les datasets à notre disposition triés par ID.<br/>\n",
    "\n",
    "Maintenant que notre banque d’image est claire, nous allons traiter les images pour en obtenir leurs histogrammes de couleur. \n",
    "La problématique avec les histogrammes de couleurs est la dimension que chaque image représente avec toutes les couleurs disponibles. SI nous décidons d’utiliser les images tels qu’elles, nous aurions des vecteurs à 16777216 dimensions, peu efficaces. \n",
    "Nous effectuons donc une quantification de couleur, permettant de trouver les couleurs les plus couramment utilisées parmis toutes les images. L’échantillon de couleurs obtenus est très grand et nous en sélectionnons aléatoirement 100000 parmi l’échantillon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05865b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Entrée :\n",
    "    - numpy array images ;\n",
    "    - int pixelNumber ;\n",
    "\n",
    "Sortie :\n",
    "    - numpy array randomRbgPixels ;\n",
    "\n",
    "Description:\n",
    "    Retourne ${pixelNumber} pixels RGB de manière aléatoire depuis\n",
    "    le dataset fourni en paramètre\n",
    "\"\"\"\n",
    "def _getRandomRgbPixels(self, pixelNumber=100000):\n",
    "    allRgbPixels = [img.reshape((-1, 3)) for img in self._imgs]\n",
    "    allRgbPixels = np.vstack(allRgbPixels)\n",
    "    randomPixelsIndexes = np.random.choice(\n",
    "        allRgbPixels.shape[0], pixelNumber, replace=False)\n",
    "    randomRbgPixels = allRgbPixels[randomPixelsIndexes, :]\n",
    "    return randomRbgPixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d357a32f",
   "metadata": {},
   "source": [
    "Nous utilisons ensuite l’algorithme des K-Means pour déterminer les N (128) couleurs les plus courantes. Nous bâtissons donc un modèle prédictif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ac8def5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Entrée :\n",
    "    - numpy array randomRbgPixels ;\n",
    "\n",
    "Sortie :\n",
    "    - KMeans kms ;\n",
    "\n",
    "Description:\n",
    "    Applique l'algorithme de KMeans sur les pixels. On regarde les occurences\n",
    "    des pixels dans l'image, afin de pouvoir batir un modèle prédictif.\n",
    "\"\"\"\n",
    "\n",
    "def _getKMeans(self, pixels):\n",
    "    nombre_pokemon = 151\n",
    "    kms = KMeans(nombre_pokemon, n_init=1, verbose=0)\n",
    "    kms.fit(pixels)\n",
    "\n",
    "    h = np.zeros((kms.n_clusters, ))\n",
    "    for i in range(kms.n_clusters):\n",
    "        r, g, b = kms.cluster_centers_[i, :]/255.0\n",
    "        h[i] = colorsys.rgb_to_hsv(r, g, b)[0]\n",
    "    idx = np.argsort(h)\n",
    "    kms.cluster_centers_ = kms.cluster_centers_[idx, :]\n",
    "\n",
    "    if (self._consts.getDisplayImagePalette()):\n",
    "        palette = kms.cluster_centers_.astype(np.uint8)\n",
    "        self._displayImg(palette.reshape((8, -1, 3)))\n",
    "\n",
    "    return kms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5f4481",
   "metadata": {},
   "source": [
    "Nous devons donc ensuite calculer l’histogramme de couleur pour chacune des images ainsi que celle de référence et les renvoyons dans notre matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "053cb7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Entrée :\n",
    "    - KMeans kms ;\n",
    "    - numpy array img ;\n",
    "\n",
    "Sortie :\n",
    "    - numpy array histogram ;\n",
    "\n",
    "Description:\n",
    "    On revoie l'histogramme des couleurs de l'image.\n",
    "\"\"\"\n",
    "\n",
    "def _getImgHistogram(self, kms, img):\n",
    "    x = np.zeros((kms.n_clusters, ))\n",
    "    idx = kms.predict(img.astype(np.float64).reshape((-1, 3)))\n",
    "    idv, v = np.unique(idx, return_counts=True)\n",
    "    x[idv] = v\n",
    "    return x/np.sum(x).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822667d0",
   "metadata": {},
   "source": [
    "Nous recherchons ensuite par similarité les distances euclidiennes entre les images d'entraînement et celles de référence et sélectionnons l’image qui à la plus grande correspondance avec celle de référence. <br/>\n",
    "\n",
    "Nous pouvons déduire quel nom de pokémon se rapproche le plus de l’image de référence et pouvons fournir un résultat à l’utilisateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "304ed4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    Entrée  : \n",
    "        - numpy array img ;\n",
    "        - int imgNumber ;\n",
    "\n",
    "    Sortie  : \n",
    "        -  int pokemonId ;\n",
    "\n",
    "    Description :\n",
    "        On compare les diagrammes de couleurs de l'image et de celles enregistrées \n",
    "        dans le dataset. On retourne le pokemonId le plus proche.\n",
    "\"\"\"\n",
    "\n",
    "def predict(self, img, imgNumber=5):\n",
    "    imgHistogram = self._getImgHistogram(self._kms, img)\n",
    "    dist = euclidean_distances([imgHistogram], self._histograms)\n",
    "    sortDist = np.argsort(dist[0, :])\n",
    "\n",
    "    foundPokemonIds = [self._ids[sortDist[i]] for i in range(imgNumber)]\n",
    "\n",
    "    return most_common(foundPokemonIds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ad2ed2",
   "metadata": {},
   "source": [
    "Comme nos images sont triées, nous pouvons récupérer le nom du Pokémon associé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a19d441",
   "metadata": {},
   "source": [
    "### Comment tester chez vous ? <a class=\"anchor\" id=\"test\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abb5645",
   "metadata": {},
   "source": [
    "Veuillez suivre les instructions rédigées dans le readme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946cb227",
   "metadata": {},
   "source": [
    "## Conclusion <a class=\"anchor\" id=\"ccl\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e56b733",
   "metadata": {},
   "source": [
    "Nous avons effectué des tests de reconnaissance sur tous les pokémons (appartenant à l'ensemble des génération mises à notre disposition). Etant donné que nos datasets d'apprentissage comportaient plus de pokémons que la génération 1, nous en avons profité pour étendre la reconnaissance à tous les Pokemons compris dans nos learning datasets.En utilisant toutes ces données, les résultats fluctuaient entre 35% et 40% de succès, celà s'expliquant par le nombre très important de Pokémons et donc de similarités entre eux.<br>\n",
    "\n",
    "Si l'on souhaite respecter notre idée initiale, il faut alors supprimer les images de Pokémons dont l'ID est supérieur à 151 présentes dans le répertoire `OneShotPokemon`. Ainsi, en restreignant nos tests aux pokémons de la la génération 1, on constate une augmentation considérable du taux de succès pour atteindre (~70% de réussite). Nous expliquons cela par le fait que moins de Pokémons sont analysés, et que donc l'IA moins de chances d'échouer sur la reconnaissance des histogrammes de couleur des Pokémons. De plus, les pokémons de la génération 1 sont plus simples en terme de couleurs, d'où une plus forte ségrégation de couleurs.<br>\n",
    "\n",
    "Nous remarquons la majorités des erreurs sont relatives à des images de pokémons ayant un important espace vide et où encore un arrrière plan de teinte similaire à leur apparence.\n",
    "|Minidraco (147)|Papilusion (12)|\n",
    "|---|---|\n",
    "|<img src = \"ScreenShots\\147.jpg\" width=350, height=350>|<img src = \"ScreenShots\\12.jpg\" width=350, height=350>|\n",
    "|L'impact de l'arrière plan est trop important <br> le fond représente ~70% de l'histogramme du pokémon|Le Pokemon possède les mêmes teintes sur ses ailes que le fond|\n",
    "\n",
    "A contrario, les Pokemons prenant le maximum de place sur l'image et possèdant des couleurs différentes que celles du fond ont des résultats bien plus satisfaisants.\n",
    "|Bulbizard (1)|Fantominus (92)|\n",
    "|---|---|\n",
    "|<img src = \"ScreenShots\\1.jpg\" width=350, height=350>|<img src = \"ScreenShots\\92.jpg\" width=350, height=350>|\n",
    "|Le Pokemon prends la majeure partie de l'image<br> Sa couleur principale est le vert|Le Pokemon prends la majeure partie de l'image<br> Sa couleur principale est le voilet/noir|\n",
    "\n",
    "Nous pensons que nous obtenons ces résultats puisque les images sont majoritairement composés de paysage en arrière plan, participant négativement à la reconnaissance de l'image puisque nous utilisons des histogrammes de couleurs. Afin d'améliorer ces résultats nous pourrions :\n",
    "- Détourer l'image en conservant seulement le Pokémon pour obtenir un histogramme de meilleur qualité.\n",
    "- Prendre des images de pokémon avec des arrières plans vides.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd22485",
   "metadata": {},
   "source": [
    "## Ressources <a class=\"anchor\" id=\"ressources\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155637a7",
   "metadata": {},
   "source": [
    "- [Google ML Practicum: Image Classification](https://developers.google.com/machine-learning/practica/image-classification?hl=en)\n",
    "- [Classifying Pokémon Images with Machine Learning](https://medium.com/m2mtechconnect/classifying-pok%C3%A9mon-images-with-machine-learning-79b9bc07c080)\n",
    "- [Regression lineaire mrmint](https://mrmint.fr/logistic-regression-machine-learning-introduction-simple)\n",
    "- [Regression lineaire whatis](https://whatis.techtarget.com/fr/definition/Regression-logistique)\n",
    "- [K-plus proche voisins](https://datascientest.com/knn)\n",
    "- [K-means](https://www.lovelyanalytics.com/2016/09/06/k-means-comment-ca-marche/)\n",
    "- [Dataset de Pokémon](https://www.kaggle.com/kvpratama/pokemon-images-dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
